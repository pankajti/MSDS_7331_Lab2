{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries required for creating models and validating them\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from time import time\n",
    "from sklearn import metrics as mt\n",
    "from IPython.html import widgets \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the data\n",
    "ccdefault=pd.read_csv('./UCI_Credit_Card.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename the columns to clearer names\n",
    "ccdefault.rename(columns={'default.payment.next.month':'DEFAULT'},inplace=True)\n",
    "ccdefault.rename(columns={'PAY_0':'PAY_1'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedShuffleSplit(n_splits=5, random_state=10, test_size=0.2,\n",
      "            train_size=0.8)\n",
      "TRAIN: [26296   633  2863 ... 15141 19066  7166] TEST: [ 5469 17052 23411 ... 24675 28588 16031]\n",
      "TRAIN: [17006  5992 28816 ... 10798 22887 23796] TEST: [  683 10937   999 ...   875  4336  2721]\n",
      "TRAIN: [ 5957 25994 14047 ...    53   805 24297] TEST: [14399 23807  6988 ...  9804 17546 23927]\n",
      "TRAIN: [11516  8559 14297 ... 14603 13364    89] TEST: [13759 19809 18958 ... 27816 11181 16164]\n",
      "TRAIN: [ 2233 17193  9866 ... 12371  9657 11083] TEST: [28935 15053 22533 ... 22298  4357 23349]\n"
     ]
    }
   ],
   "source": [
    "#Cleaning of data\n",
    "cc = ccdefault.copy() # taking a copy in memory\n",
    "if 'DEFAULT' in cc:\n",
    "    y = cc['DEFAULT'].values\n",
    "    del cc['DEFAULT']\n",
    "    del cc['BILL_AMT1']\n",
    "    del cc['BILL_AMT2']\n",
    "    del cc['BILL_AMT3']\n",
    "    del cc['BILL_AMT4']\n",
    "    del cc['BILL_AMT5']\n",
    "    del cc['BILL_AMT6']\n",
    "    X = cc.values\n",
    "num_cv_iterations = 5\n",
    "num_instances = len(y)\n",
    "cv_object = StratifiedShuffleSplit(n_splits = num_cv_iterations,\n",
    "test_size = 0.20, train_size = 0.80, random_state=10)\n",
    "cv_object.get_n_splits(X, y)\n",
    "print(cv_object)\n",
    "for train_index, test_index in cv_object.split(X, y):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale the data so the distance metric is not affected by the range of explanatory variables\n",
    "scl_obj = StandardScaler()\n",
    "scl_obj.fit(X_train) \n",
    "\n",
    "X_train_scaled = scl_obj.transform(X_train) # apply to training\n",
    "X_test_scaled = scl_obj.transform(X_test) # apply those means and std to the test set (without snooping at the test set values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k =  10 and metric = Euclidean: \n",
      "accuracy: 0.7695\n",
      "[[4602   71]\n",
      " [1312   15]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.98      0.87      4673\n",
      "           1       0.17      0.01      0.02      1327\n",
      "\n",
      "    accuracy                           0.77      6000\n",
      "   macro avg       0.48      0.50      0.45      6000\n",
      "weighted avg       0.64      0.77      0.68      6000\n",
      "\n",
      "For k =  25 and metric = Euclidean: \n",
      "accuracy: 0.7781666666666667\n",
      "[[4667    6]\n",
      " [1325    2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.88      4673\n",
      "           1       0.25      0.00      0.00      1327\n",
      "\n",
      "    accuracy                           0.78      6000\n",
      "   macro avg       0.51      0.50      0.44      6000\n",
      "weighted avg       0.66      0.78      0.68      6000\n",
      "\n",
      "For k =  50 and metric = Euclidean: \n",
      "accuracy: 0.7788333333333334\n",
      "[[4673    0]\n",
      " [1327    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.88      4673\n",
      "           1       0.00      0.00      0.00      1327\n",
      "\n",
      "    accuracy                           0.78      6000\n",
      "   macro avg       0.39      0.50      0.44      6000\n",
      "weighted avg       0.61      0.78      0.68      6000\n",
      "\n",
      "For k =  100 and metric = Euclidean: \n",
      "accuracy: 0.7788333333333334\n",
      "[[4673    0]\n",
      " [1327    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.88      4673\n",
      "           1       0.00      0.00      0.00      1327\n",
      "\n",
      "    accuracy                           0.78      6000\n",
      "   macro avg       0.39      0.50      0.44      6000\n",
      "weighted avg       0.61      0.78      0.68      6000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Using Euclidean distance metric:\n",
    "\n",
    "parameters = [10, 25, 50, 100]\n",
    "for K in parameters:\n",
    "    print(\"For k = \", K, \"and metric = Euclidean: \")\n",
    "    knn = KNeighborsClassifier(n_neighbors=K, weights='uniform', metric='euclidean')\n",
    "    knn.fit(X_train_scaled,y_train)\n",
    "    y_hat = knn.predict(X_test_scaled)\n",
    "    acc = mt.accuracy_score(y_test,y_hat)\n",
    "    conf = mt.confusion_matrix(y_test,y_hat)\n",
    "    print('accuracy:', acc )\n",
    "    print(conf )\n",
    "    ClassReport = mt.classification_report(y_test,y_hat)\n",
    "    print(ClassReport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k =  10 and metric = Cosine: \n",
      "accuracy: 0.7703333333333333\n",
      "[[4605   68]\n",
      " [1310   17]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.99      0.87      4673\n",
      "           1       0.20      0.01      0.02      1327\n",
      "\n",
      "    accuracy                           0.77      6000\n",
      "   macro avg       0.49      0.50      0.45      6000\n",
      "weighted avg       0.65      0.77      0.68      6000\n",
      "\n",
      "For k =  25 and metric = Cosine: \n",
      "accuracy: 0.7775\n",
      "[[4665    8]\n",
      " [1327    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.87      4673\n",
      "           1       0.00      0.00      0.00      1327\n",
      "\n",
      "    accuracy                           0.78      6000\n",
      "   macro avg       0.39      0.50      0.44      6000\n",
      "weighted avg       0.61      0.78      0.68      6000\n",
      "\n",
      "For k =  50 and metric = Cosine: \n",
      "accuracy: 0.7788333333333334\n",
      "[[4673    0]\n",
      " [1327    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.88      4673\n",
      "           1       0.00      0.00      0.00      1327\n",
      "\n",
      "    accuracy                           0.78      6000\n",
      "   macro avg       0.39      0.50      0.44      6000\n",
      "weighted avg       0.61      0.78      0.68      6000\n",
      "\n",
      "For k =  100 and metric = Cosine: \n",
      "accuracy: 0.7788333333333334\n",
      "[[4673    0]\n",
      " [1327    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.88      4673\n",
      "           1       0.00      0.00      0.00      1327\n",
      "\n",
      "    accuracy                           0.78      6000\n",
      "   macro avg       0.39      0.50      0.44      6000\n",
      "weighted avg       0.61      0.78      0.68      6000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Using cosine distance metric\n",
    "\n",
    "parameters = [10, 25, 50, 100]\n",
    "for K in parameters:\n",
    "    print(\"For k = \", K, \"and metric = Cosine: \")\n",
    "    knn = KNeighborsClassifier(n_neighbors=K, weights='uniform', metric='cosine')\n",
    "    knn.fit(X_train_scaled,y_train)\n",
    "    y_hat = knn.predict(X_test_scaled)\n",
    "    acc = mt.accuracy_score(y_test,y_hat)\n",
    "    conf = mt.confusion_matrix(y_test,y_hat)\n",
    "    print('accuracy:', acc )\n",
    "    print(conf )\n",
    "    ClassReport = mt.classification_report(y_test,y_hat)\n",
    "    print(ClassReport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k =  10 and metric = Manhattan: \n",
      "accuracy: 0.769\n",
      "[[4605   68]\n",
      " [1318    9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.99      0.87      4673\n",
      "           1       0.12      0.01      0.01      1327\n",
      "\n",
      "    accuracy                           0.77      6000\n",
      "   macro avg       0.45      0.50      0.44      6000\n",
      "weighted avg       0.63      0.77      0.68      6000\n",
      "\n",
      "For k =  25 and metric = Manhattan: \n",
      "accuracy: 0.7785\n",
      "[[4670    3]\n",
      " [1326    1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.88      4673\n",
      "           1       0.25      0.00      0.00      1327\n",
      "\n",
      "    accuracy                           0.78      6000\n",
      "   macro avg       0.51      0.50      0.44      6000\n",
      "weighted avg       0.66      0.78      0.68      6000\n",
      "\n",
      "For k =  50 and metric = Manhattan: \n",
      "accuracy: 0.7788333333333334\n",
      "[[4673    0]\n",
      " [1327    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.88      4673\n",
      "           1       0.00      0.00      0.00      1327\n",
      "\n",
      "    accuracy                           0.78      6000\n",
      "   macro avg       0.39      0.50      0.44      6000\n",
      "weighted avg       0.61      0.78      0.68      6000\n",
      "\n",
      "For k =  100 and metric = Manhattan: \n",
      "accuracy: 0.7788333333333334\n",
      "[[4673    0]\n",
      " [1327    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.88      4673\n",
      "           1       0.00      0.00      0.00      1327\n",
      "\n",
      "    accuracy                           0.78      6000\n",
      "   macro avg       0.39      0.50      0.44      6000\n",
      "weighted avg       0.61      0.78      0.68      6000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Using manhattan distance metric\n",
    "\n",
    "parameters = [10, 25, 50, 100]\n",
    "for K in parameters:\n",
    "    print(\"For k = \", K, \"and metric = Manhattan: \")\n",
    "    knn = KNeighborsClassifier(n_neighbors=K, weights='uniform', metric='manhattan')\n",
    "    knn.fit(X_train_scaled,y_train)\n",
    "    y_hat = knn.predict(X_test_scaled)\n",
    "    acc = mt.accuracy_score(y_test,y_hat)\n",
    "    conf = mt.confusion_matrix(y_test,y_hat)\n",
    "    print('accuracy:', acc )\n",
    "    print(conf )\n",
    "    ClassReport = mt.classification_report(y_test,y_hat)\n",
    "    print(ClassReport)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "Discussion on relevance of distance metric\n",
    "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4978658/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
