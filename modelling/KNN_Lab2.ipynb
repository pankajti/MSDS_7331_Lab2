{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pankaj/anaconda/envs/ML7331/lib/python3.7/site-packages/IPython/html.py:14: ShimWarning: The `IPython.html` package has been deprecated since IPython 4.0. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n",
      "  \"`IPython.html.widgets` has moved to `ipywidgets`.\", ShimWarning)\n"
     ]
    }
   ],
   "source": [
    "# Import libraries required for creating models and validating them\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from time import time\n",
    "from sklearn import metrics as mt\n",
    "from IPython.html import widgets \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the data\n",
    "ccdefault=pd.read_csv('./UCI_Credit_Card.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename the columns to clearer names\n",
    "ccdefault.rename(columns={'default.payment.next.month':'DEFAULT'},inplace=True)\n",
    "ccdefault.rename(columns={'PAY_0':'PAY_1'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedShuffleSplit(n_splits=5, random_state=10, test_size=0.2,\n",
      "            train_size=0.8)\n",
      "TRAIN: [26296   633  2863 ... 15141 19066  7166] TEST: [ 5469 17052 23411 ... 24675 28588 16031]\n",
      "TRAIN: [17006  5992 28816 ... 10798 22887 23796] TEST: [  683 10937   999 ...   875  4336  2721]\n",
      "TRAIN: [ 5957 25994 14047 ...    53   805 24297] TEST: [14399 23807  6988 ...  9804 17546 23927]\n",
      "TRAIN: [11516  8559 14297 ... 14603 13364    89] TEST: [13759 19809 18958 ... 27816 11181 16164]\n",
      "TRAIN: [ 2233 17193  9866 ... 12371  9657 11083] TEST: [28935 15053 22533 ... 22298  4357 23349]\n"
     ]
    }
   ],
   "source": [
    "#Cleaning of data\n",
    "cc = ccdefault.copy() # taking a copy in memory\n",
    "if 'DEFAULT' in cc:\n",
    "    y = cc['DEFAULT'].values\n",
    "    del cc['DEFAULT']\n",
    "    del cc['BILL_AMT1']\n",
    "    del cc['BILL_AMT2']\n",
    "    del cc['BILL_AMT3']\n",
    "    del cc['BILL_AMT4']\n",
    "    del cc['BILL_AMT5']\n",
    "    del cc['BILL_AMT6']\n",
    "    X = cc.values\n",
    "num_cv_iterations = 5\n",
    "num_instances = len(y)\n",
    "cv_object = StratifiedShuffleSplit(n_splits = num_cv_iterations,\n",
    "test_size = 0.20, train_size = 0.80, random_state=10)\n",
    "cv_object.get_n_splits(X, y)\n",
    "print(cv_object)\n",
    "for train_index, test_index in cv_object.split(X, y):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale the data so the distance metric is not affected by the range of explanatory variables\n",
    "scl_obj = StandardScaler()\n",
    "scl_obj.fit(X_train) \n",
    "\n",
    "X_train_scaled = scl_obj.transform(X_train) # apply to training\n",
    "X_test_scaled = scl_obj.transform(X_test) # apply those means and std to the test set (without snooping at the test set values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to collect max accuracy \n",
    "max_acc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k =  10 and metric = Euclidean: \n",
      "accuracy: 0.8065\n",
      "[[4466  207]\n",
      " [ 954  373]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.96      0.88      4673\n",
      "           1       0.64      0.28      0.39      1327\n",
      "\n",
      "    accuracy                           0.81      6000\n",
      "   macro avg       0.73      0.62      0.64      6000\n",
      "weighted avg       0.78      0.81      0.78      6000\n",
      "\n",
      "For k =  20 and metric = Euclidean: \n",
      "accuracy: 0.8101666666666667\n",
      "[[4456  217]\n",
      " [ 922  405]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.89      4673\n",
      "           1       0.65      0.31      0.42      1327\n",
      "\n",
      "    accuracy                           0.81      6000\n",
      "   macro avg       0.74      0.63      0.65      6000\n",
      "weighted avg       0.79      0.81      0.78      6000\n",
      "\n",
      "For k =  50 and metric = Euclidean: \n",
      "accuracy: 0.8111666666666667\n",
      "[[4479  194]\n",
      " [ 939  388]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89      4673\n",
      "           1       0.67      0.29      0.41      1327\n",
      "\n",
      "    accuracy                           0.81      6000\n",
      "   macro avg       0.75      0.63      0.65      6000\n",
      "weighted avg       0.79      0.81      0.78      6000\n",
      "\n",
      "For k =  100 and metric = Euclidean: \n",
      "accuracy: 0.81\n",
      "[[4491  182]\n",
      " [ 958  369]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.96      0.89      4673\n",
      "           1       0.67      0.28      0.39      1327\n",
      "\n",
      "    accuracy                           0.81      6000\n",
      "   macro avg       0.75      0.62      0.64      6000\n",
      "weighted avg       0.79      0.81      0.78      6000\n",
      "\n",
      "0.8111666666666667\n"
     ]
    }
   ],
   "source": [
    "parameters = [10, 20, 50, 100]\n",
    "for K in parameters:\n",
    "    print(\"For k = \", K, \"and metric = Euclidean: \")\n",
    "    knn = KNeighborsClassifier(n_neighbors=K, weights='uniform', metric='euclidean')\n",
    "    knn.fit(X_train_scaled,y_train)\n",
    "    y_hat = knn.predict(X_test_scaled)\n",
    "    acc = mt.accuracy_score(y_test,y_hat)\n",
    "    conf = mt.confusion_matrix(y_test,y_hat)\n",
    "    print('accuracy:', acc )\n",
    "    print(conf)\n",
    "    ClassReport = mt.classification_report(y_test,y_hat)\n",
    "    print(ClassReport)\n",
    "    max_acc = (acc) if acc>max_acc else (max_acc)\n",
    "    \n",
    "print(max_acc)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k =  10 and metric = Cosine: \n",
      "accuracy: 0.8041666666666667\n",
      "[[4437  236]\n",
      " [ 939  388]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.88      4673\n",
      "           1       0.62      0.29      0.40      1327\n",
      "\n",
      "    accuracy                           0.80      6000\n",
      "   macro avg       0.72      0.62      0.64      6000\n",
      "weighted avg       0.78      0.80      0.78      6000\n",
      "\n",
      "For k =  20 and metric = Cosine: \n",
      "accuracy: 0.8121666666666667\n",
      "[[4435  238]\n",
      " [ 889  438]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.89      4673\n",
      "           1       0.65      0.33      0.44      1327\n",
      "\n",
      "    accuracy                           0.81      6000\n",
      "   macro avg       0.74      0.64      0.66      6000\n",
      "weighted avg       0.79      0.81      0.79      6000\n",
      "\n",
      "For k =  50 and metric = Cosine: \n",
      "accuracy: 0.8113333333333334\n",
      "[[4429  244]\n",
      " [ 888  439]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.89      4673\n",
      "           1       0.64      0.33      0.44      1327\n",
      "\n",
      "    accuracy                           0.81      6000\n",
      "   macro avg       0.74      0.64      0.66      6000\n",
      "weighted avg       0.79      0.81      0.79      6000\n",
      "\n",
      "For k =  100 and metric = Cosine: \n",
      "accuracy: 0.8118333333333333\n",
      "[[4424  249]\n",
      " [ 880  447]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.89      4673\n",
      "           1       0.64      0.34      0.44      1327\n",
      "\n",
      "    accuracy                           0.81      6000\n",
      "   macro avg       0.74      0.64      0.66      6000\n",
      "weighted avg       0.79      0.81      0.79      6000\n",
      "\n",
      "0.8121666666666667\n"
     ]
    }
   ],
   "source": [
    "parameters = [10, 20, 50, 100]\n",
    "for K in parameters:\n",
    "    print(\"For k = \", K, \"and metric = Cosine: \")\n",
    "    knn = KNeighborsClassifier(n_neighbors=K, weights='uniform', metric='cosine')\n",
    "    knn.fit(X_train_scaled,y_train)\n",
    "    y_hat = knn.predict(X_test_scaled)\n",
    "    acc = mt.accuracy_score(y_test,y_hat)\n",
    "    conf = mt.confusion_matrix(y_test,y_hat)\n",
    "    print('accuracy:', acc )\n",
    "    print(conf )\n",
    "    ClassReport = mt.classification_report(y_test,y_hat)\n",
    "    print(ClassReport)\n",
    "    max_acc = (acc) if acc>max_acc else (max_acc)\n",
    "    \n",
    "print(max_acc)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k =  10 and metric = Manhattan: \n",
      "accuracy: 0.8026666666666666\n",
      "[[4457  216]\n",
      " [ 968  359]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88      4673\n",
      "           1       0.62      0.27      0.38      1327\n",
      "\n",
      "    accuracy                           0.80      6000\n",
      "   macro avg       0.72      0.61      0.63      6000\n",
      "weighted avg       0.78      0.80      0.77      6000\n",
      "\n",
      "For k =  20 and metric = Manhattan: \n",
      "accuracy: 0.8078333333333333\n",
      "[[4466  207]\n",
      " [ 946  381]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89      4673\n",
      "           1       0.65      0.29      0.40      1327\n",
      "\n",
      "    accuracy                           0.81      6000\n",
      "   macro avg       0.74      0.62      0.64      6000\n",
      "weighted avg       0.79      0.81      0.78      6000\n",
      "\n",
      "For k =  50 and metric = Manhattan: \n",
      "accuracy: 0.8103333333333333\n",
      "[[4488  185]\n",
      " [ 953  374]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.96      0.89      4673\n",
      "           1       0.67      0.28      0.40      1327\n",
      "\n",
      "    accuracy                           0.81      6000\n",
      "   macro avg       0.75      0.62      0.64      6000\n",
      "weighted avg       0.79      0.81      0.78      6000\n",
      "\n",
      "For k =  100 and metric = Manhattan: \n",
      "accuracy: 0.8088333333333333\n",
      "[[4487  186]\n",
      " [ 961  366]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.96      0.89      4673\n",
      "           1       0.66      0.28      0.39      1327\n",
      "\n",
      "    accuracy                           0.81      6000\n",
      "   macro avg       0.74      0.62      0.64      6000\n",
      "weighted avg       0.79      0.81      0.78      6000\n",
      "\n",
      "0.8121666666666667\n"
     ]
    }
   ],
   "source": [
    "parameters = [10, 20, 50, 100]\n",
    "for K in parameters:\n",
    "    print(\"For k = \", K, \"and metric = Manhattan: \")\n",
    "    knn = KNeighborsClassifier(n_neighbors=K, weights='uniform', metric='manhattan')\n",
    "    knn.fit(X_train_scaled,y_train)\n",
    "    y_hat = knn.predict(X_test_scaled)\n",
    "    acc = mt.accuracy_score(y_test,y_hat)\n",
    "    conf = mt.confusion_matrix(y_test,y_hat)\n",
    "    print('accuracy:', acc )\n",
    "    print(conf )\n",
    "    ClassReport = mt.classification_report(y_test,y_hat)\n",
    "    print(ClassReport)\n",
    "    max_acc = (acc) if acc>max_acc else (max_acc)\n",
    "    \n",
    "print(max_acc)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
